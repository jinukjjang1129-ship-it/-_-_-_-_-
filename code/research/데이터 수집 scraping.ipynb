{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e9ad16a-f926-411c-b688-42dbfb48af0a",
   "metadata": {},
   "source": [
    "# 트럼프 트위터 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b84a5342-e058-4618-b38f-92929e72ac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페이지 열기: https://www.thetrumparchive.com/?utm_source=chatgpt.com&retweet=%22false%22&device=%22All+devices%22&resultOffset=0&resultssortOption=%22Latest%22&startDate=%222016-11-08%22&endDate=%222017-01-20%22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shinchaewon\\AppData\\Local\\Temp\\ipykernel_15004\\413371047.py:74: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  inner_soup = BeautifulSoup(inner_html, \"html.parser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 25\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 50\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 75\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 100\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 125\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 150\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 175\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 200\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 225\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 250\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 275\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 300\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 325\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 350\n",
      "이번 라운드에서 새로 수집한 트윗 수: 14\n",
      "현재까지 고유 트윗 수(id 기준): 364\n",
      "이번 라운드에서 새로 수집한 트윗 수: 0\n",
      "현재까지 고유 트윗 수(id 기준): 364\n",
      "새로 나온 트윗 없음. empty_scrolls=1\n",
      "이번 라운드에서 새로 수집한 트윗 수: 0\n",
      "현재까지 고유 트윗 수(id 기준): 364\n",
      "새로 나온 트윗 없음. empty_scrolls=2\n",
      "이번 라운드에서 새로 수집한 트윗 수: 0\n",
      "현재까지 고유 트윗 수(id 기준): 364\n",
      "새로 나온 트윗 없음. empty_scrolls=3\n",
      "이번 라운드에서 새로 수집한 트윗 수: 0\n",
      "현재까지 고유 트윗 수(id 기준): 364\n",
      "새로 나온 트윗 없음. empty_scrolls=4\n",
      "이번 라운드에서 새로 수집한 트윗 수: 0\n",
      "현재까지 고유 트윗 수(id 기준): 364\n",
      "새로 나온 트윗 없음. empty_scrolls=5\n",
      "여러 번 스크롤해도 새 트윗이 안 나와서 종료.\n",
      "\n",
      "최종 수집된 트윗 개수(고유 id 기준): 364\n",
      "중복 제거 후 최종 행 수: 364\n",
      "CSV 저장 완료\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import json, html\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import InvalidSessionIdException, WebDriverException\n",
    "\n",
    "BASE_URL = (\n",
    "    \"https://www.thetrumparchive.com/?utm_source=chatgpt.com\"\n",
    "    \"&retweet=%22false%22\"\n",
    "    \"&device=%22All+devices%22\"\n",
    "    \"&resultOffset=0\"\n",
    "    \"&resultssortOption=%22Latest%22\"\n",
    "    \"&startDate=%222016-11-08%22\"\n",
    "    \"&endDate=%222017-01-20%22\"\n",
    ")\n",
    "\n",
    "\n",
    "SCROLL_PAUSE_SEC = 2.0     # 스크롤 후 대기 시간\n",
    "MAX_EMPTY_SCROLLS = 5      # 새로 나오는 트윗이 없을 때 몇 번까지 버틸지\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "all_tweets = []\n",
    "seen_ids = set()\n",
    "\n",
    "try:\n",
    "    print(\"페이지 열기:\", BASE_URL)\n",
    "    driver.get(BASE_URL)\n",
    "\n",
    "    # 첫 로딩에서 트윗 요소가 뜰 때까지 대기\n",
    "    try:\n",
    "        wait.until(\n",
    "            EC.presence_of_all_elements_located(\n",
    "                (By.CSS_SELECTOR, \"div.ttaTweet\")\n",
    "            )\n",
    "        )\n",
    "    except Exception:\n",
    "        print(\"처음 로딩에서 트윗 요소를 찾지 못했음. 종료.\")\n",
    "    \n",
    "    empty_scrolls = 0\n",
    "\n",
    "    while True:\n",
    "        # 현재까지 페이지 전체 HTML 파싱\n",
    "        html_source = driver.page_source\n",
    "        soup = BeautifulSoup(html_source, \"html.parser\")\n",
    "\n",
    "        new_in_this_round = 0\n",
    "        for div in soup.select(\"div.ttaTweet\"):\n",
    "            raw = div.get(\"data-tweet\")\n",
    "            if not raw:\n",
    "                continue\n",
    "\n",
    "            data = json.loads(html.unescape(raw))\n",
    "            ts = data.get(\"date\")\n",
    "            tweet_id = data.get(\"id\")\n",
    "\n",
    "            if ts is None or tweet_id is None:\n",
    "                continue\n",
    "\n",
    "            # 중복 체크\n",
    "            if tweet_id in seen_ids:\n",
    "                continue\n",
    "            seen_ids.add(tweet_id)\n",
    "\n",
    "            dt_utc = datetime.fromtimestamp(ts / 1000.0, tz=timezone.utc)\n",
    "\n",
    "            inner_html = html.unescape(data.get(\"text\", \"\"))\n",
    "            inner_soup = BeautifulSoup(inner_html, \"html.parser\")\n",
    "            text = inner_soup.get_text(\" \", strip=True)\n",
    "\n",
    "            t = {\n",
    "                \"datetime_utc\": dt_utc.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"id\": tweet_id,\n",
    "                \"text\": text,\n",
    "                \"retweets\": data.get(\"retweets\"),\n",
    "                \"favorites\": data.get(\"favorites\"),\n",
    "                \"source\": data.get(\"source\"),\n",
    "            }\n",
    "            all_tweets.append(t)\n",
    "            new_in_this_round += 1\n",
    "\n",
    "        print(f\"이번 라운드에서 새로 수집한 트윗 수: {new_in_this_round}\")\n",
    "        print(f\"현재까지 고유 트윗 수(id 기준): {len(seen_ids)}\")\n",
    "\n",
    "        if new_in_this_round == 0:\n",
    "            empty_scrolls += 1\n",
    "            print(f\"새로 나온 트윗 없음. empty_scrolls={empty_scrolls}\")\n",
    "            if empty_scrolls >= MAX_EMPTY_SCROLLS:\n",
    "                print(\"여러 번 스크롤해도 새 트윗이 안 나와서 종료.\")\n",
    "                break\n",
    "        else:\n",
    "            empty_scrolls = 0\n",
    "\n",
    "        # 스크롤 맨 아래로 내려서 다음 트윗들 로딩 유도\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_SEC)\n",
    "\n",
    "except InvalidSessionIdException:\n",
    "    print(\"중간에 브라우저 세션이 끊어졌어요. 여기까지 저장합니다.\")\n",
    "\n",
    "finally:\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(\"\\n최종 수집된 트윗 개수(고유 id 기준):\", len(seen_ids))\n",
    "    df = pd.DataFrame(all_tweets)\n",
    "\n",
    "    if not df.empty:\n",
    "        df = df.drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
    "        print(\"중복 제거 후 최종 행 수:\", len(df))\n",
    "\n",
    "    df.to_csv(\n",
    "        r\"C:\\Users\\shinchaewon\\Desktop\\trump_tweets_2017_2021_full.csv\",\n",
    "        index=False,\n",
    "        encoding=\"utf-8-sig\",\n",
    "    )\n",
    "    print(\"CSV 저장 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a730cf4-42e4-4a87-9a07-88decf128990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행 수: 9325\n",
      "고유 id 개수: 9325\n",
      "중복된 id 개수: 0\n",
      "중복 예시:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\shinchaewon\\Desktop\\trump_tweets_2017_2021_full.csv\")\n",
    "\n",
    "print(\"행 수:\", len(df))\n",
    "print(\"고유 id 개수:\", df['id'].nunique())\n",
    "\n",
    "vc = df['id'].value_counts()\n",
    "print(\"중복된 id 개수:\", (vc > 1).sum())\n",
    "print(\"중복 예시:\")\n",
    "print(vc[vc > 1].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a4e3e1e-a75d-40aa-8e31-578c107efe10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페이지 열기: https://www.thetrumparchive.com/?utm_source=chatgpt.com&startDate=%222017-01-20%22&endDate=%222019-07-05%22&retweet=%22false%22&device=%22All+devices%22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shinchaewon\\AppData\\Local\\Temp\\ipykernel_15444\\1406428268.py:60: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  inner_soup = BeautifulSoup(inner_html, \"html.parser\")\n",
      "C:\\Users\\shinchaewon\\AppData\\Local\\Temp\\ipykernel_15444\\1406428268.py:60: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  inner_soup = BeautifulSoup(inner_html, \"html.parser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 25\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 50\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 75\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 100\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 125\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 150\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 175\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 200\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 225\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 250\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 275\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 300\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 325\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 350\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 375\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 400\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 425\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 450\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 475\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 500\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 525\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 550\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 575\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 600\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 625\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 650\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 675\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 700\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 725\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 750\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 775\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 800\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 825\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 850\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 875\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 900\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 925\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 950\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 975\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1000\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1025\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1050\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1075\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1100\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1125\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1150\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1175\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1200\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1225\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1250\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1275\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1300\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1325\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1350\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1375\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1400\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1425\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1450\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1475\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1500\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1525\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1550\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1575\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1600\n",
      "이번 라운드에서 새로 수집한 트윗 수: 25\n",
      "현재까지 고유 트윗 수(id 기준): 1625\n",
      "중간에 브라우저 세션이 끊어졌어요. 여기까지 저장합니다.\n",
      "\n",
      "최종 수집된 트윗 개수(고유 id 기준): 1625\n",
      "중복 제거 후 최종 행 수: 1625\n",
      "CSV 저장 완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BASE_URL = (\n",
    "    \"https://www.thetrumparchive.com/?utm_source=chatgpt.com\"\n",
    "    \"&startDate=%222017-01-20%22\"\n",
    "    \"&endDate=%222019-07-05%22\"\n",
    "    \"&retweet=%22false%22\"\n",
    "    \"&device=%22All+devices%22\"\n",
    ")\n",
    "\n",
    "SCROLL_PAUSE_SEC = 2.0     # 스크롤 후 대기 시간\n",
    "MAX_EMPTY_SCROLLS = 5      # 새로 나오는 트윗이 없을 때 몇 번까지 버틸지\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "all_tweets = []\n",
    "seen_ids = set()\n",
    "\n",
    "try:\n",
    "    print(\"페이지 열기:\", BASE_URL)\n",
    "    driver.get(BASE_URL)\n",
    "\n",
    "    # 첫 로딩에서 트윗 요소가 뜰 때까지 대기\n",
    "    try:\n",
    "        wait.until(\n",
    "            EC.presence_of_all_elements_located(\n",
    "                (By.CSS_SELECTOR, \"div.ttaTweet\")\n",
    "            )\n",
    "        )\n",
    "    except Exception:\n",
    "        print(\"처음 로딩에서 트윗 요소를 찾지 못했음. 종료.\")\n",
    "    \n",
    "    empty_scrolls = 0\n",
    "\n",
    "    while True:\n",
    "        # 현재까지 페이지 전체 HTML 파싱\n",
    "        html_source = driver.page_source\n",
    "        soup = BeautifulSoup(html_source, \"html.parser\")\n",
    "\n",
    "        new_in_this_round = 0\n",
    "        for div in soup.select(\"div.ttaTweet\"):\n",
    "            raw = div.get(\"data-tweet\")\n",
    "            if not raw:\n",
    "                continue\n",
    "\n",
    "            data = json.loads(html.unescape(raw))\n",
    "            ts = data.get(\"date\")\n",
    "            tweet_id = data.get(\"id\")\n",
    "\n",
    "            if ts is None or tweet_id is None:\n",
    "                continue\n",
    "\n",
    "            # 중복 체크\n",
    "            if tweet_id in seen_ids:\n",
    "                continue\n",
    "            seen_ids.add(tweet_id)\n",
    "\n",
    "            dt_utc = datetime.fromtimestamp(ts / 1000.0, tz=timezone.utc)\n",
    "\n",
    "            inner_html = html.unescape(data.get(\"text\", \"\"))\n",
    "            inner_soup = BeautifulSoup(inner_html, \"html.parser\")\n",
    "            text = inner_soup.get_text(\" \", strip=True)\n",
    "\n",
    "            t = {\n",
    "                \"datetime_utc\": dt_utc.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"id\": tweet_id,\n",
    "                \"text\": text,\n",
    "                \"retweets\": data.get(\"retweets\"),\n",
    "                \"favorites\": data.get(\"favorites\"),\n",
    "                \"source\": data.get(\"source\"),\n",
    "            }\n",
    "            all_tweets.append(t)\n",
    "            new_in_this_round += 1\n",
    "\n",
    "        print(f\"이번 라운드에서 새로 수집한 트윗 수: {new_in_this_round}\")\n",
    "        print(f\"현재까지 고유 트윗 수(id 기준): {len(seen_ids)}\")\n",
    "\n",
    "        if new_in_this_round == 0:\n",
    "            empty_scrolls += 1\n",
    "            print(f\"새로 나온 트윗 없음. empty_scrolls={empty_scrolls}\")\n",
    "            if empty_scrolls >= MAX_EMPTY_SCROLLS:\n",
    "                print(\"여러 번 스크롤해도 새 트윗이 안 나와서 종료.\")\n",
    "                break\n",
    "        else:\n",
    "            empty_scrolls = 0\n",
    "\n",
    "        # 스크롤 맨 아래로 내려서 다음 트윗들 로딩 유도\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_SEC)\n",
    "\n",
    "except InvalidSessionIdException:\n",
    "    print(\"중간에 브라우저 세션이 끊어졌어요. 여기까지 저장합니다.\")\n",
    "\n",
    "finally:\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(\"\\n최종 수집된 트윗 개수(고유 id 기준):\", len(seen_ids))\n",
    "    df = pd.DataFrame(all_tweets)\n",
    "\n",
    "    if not df.empty:\n",
    "        df = df.drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
    "        print(\"중복 제거 후 최종 행 수:\", len(df))\n",
    "\n",
    "    df.to_csv(\n",
    "        r\"C:\\Users\\shinchaewon\\Desktop\\trump_tweets_2017_2019_full.csv\",\n",
    "        index=False,\n",
    "        encoding=\"utf-8-sig\",\n",
    "    )\n",
    "    print(\"CSV 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ec323ce-21a2-4355-85e9-a19e339a4af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페이지 열기: https://www.thetrumparchive.com/?utm_source=chatgpt.com&startDate=%222017-01-20%22&endDate=%222019-02-10%22&retweet=%22false%22&device=%22All+devices%22\n",
      "스크롤 타겟 찾음\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shinchaewon\\AppData\\Local\\Temp\\ipykernel_15444\\3026932916.py:82: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  inner_soup = BeautifulSoup(inner_html, \"html.parser\")\n",
      "C:\\Users\\shinchaewon\\AppData\\Local\\Temp\\ipykernel_15444\\3026932916.py:82: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  inner_soup = BeautifulSoup(inner_html, \"html.parser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 50\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 75\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 100\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 125\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 150\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 175\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 200\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 225\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 250\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 275\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 300\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 325\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 350\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 375\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 400\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 425\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 450\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 475\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 500\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 525\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 550\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 575\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 600\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 625\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 650\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 675\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 700\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 725\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 750\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 775\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 800\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 825\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 850\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 875\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 900\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 925\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 950\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 975\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1000\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1025\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1050\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1075\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1100\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1125\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1150\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1175\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1200\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1225\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1250\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1275\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1300\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1325\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1350\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1375\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1400\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1425\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1450\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1475\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1500\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1525\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1550\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1575\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1600\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1625\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1650\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1675\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1700\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1725\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1750\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1775\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1800\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1825\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1850\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1875\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1900\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1925\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1950\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 1975\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2000\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2025\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2050\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2075\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2100\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2125\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2150\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2175\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2200\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2225\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2250\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2275\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2300\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2325\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2350\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2375\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2400\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2425\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2450\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2475\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2500\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2525\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2550\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2575\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2600\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2625\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2650\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2675\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2700\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2725\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2750\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2775\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2800\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2825\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2850\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2875\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2900\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2925\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2950\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 2975\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3000\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3025\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3050\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3075\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3100\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3125\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3150\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3175\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3200\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3225\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3250\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3275\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3300\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3325\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3350\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3375\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3400\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3425\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3450\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3475\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3500\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3525\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3550\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3575\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3600\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3625\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3650\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3675\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3700\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3725\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3750\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3775\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3800\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3825\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3850\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3875\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3900\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3925\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3950\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 3975\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4000\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4025\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4050\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4075\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4100\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4125\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4150\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4175\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4200\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4225\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4250\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4275\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4300\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4325\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4350\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4375\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4400\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4425\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4450\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4475\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4500\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4525\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4550\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4575\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4600\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4625\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4650\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4675\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4700\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4725\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4750\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4775\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4800\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4825\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4850\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4875\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4900\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4925\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4950\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 4975\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5000\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5025\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5050\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5075\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5100\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5125\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5150\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5175\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5200\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5225\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5250\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5275\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5300\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5325\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5350\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5375\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5400\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5425\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5450\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5475\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5500\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5525\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5550\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5575\n",
      "이번 라운드 새 트윗: 25 | 누적 고유 id: 5600\n",
      "이번 라운드 새 트윗: 10 | 누적 고유 id: 5610\n",
      "이번 라운드 새 트윗: 0 | 누적 고유 id: 5610\n",
      "새로 나온 트윗 없음. empty_scrolls=1\n",
      "이번 라운드 새 트윗: 0 | 누적 고유 id: 5610\n",
      "새로 나온 트윗 없음. empty_scrolls=2\n",
      "이번 라운드 새 트윗: 0 | 누적 고유 id: 5610\n",
      "새로 나온 트윗 없음. empty_scrolls=3\n",
      "이번 라운드 새 트윗: 0 | 누적 고유 id: 5610\n",
      "새로 나온 트윗 없음. empty_scrolls=4\n",
      "이번 라운드 새 트윗: 0 | 누적 고유 id: 5610\n",
      "새로 나온 트윗 없음. empty_scrolls=5\n",
      "이번 라운드 새 트윗: 0 | 누적 고유 id: 5610\n",
      "새로 나온 트윗 없음. empty_scrolls=6\n",
      "이번 라운드 새 트윗: 0 | 누적 고유 id: 5610\n",
      "새로 나온 트윗 없음. empty_scrolls=7\n",
      "이번 라운드 새 트윗: 0 | 누적 고유 id: 5610\n",
      "새로 나온 트윗 없음. empty_scrolls=8\n",
      "이번 라운드 새 트윗: 0 | 누적 고유 id: 5610\n",
      "새로 나온 트윗 없음. empty_scrolls=9\n",
      "이번 라운드 새 트윗: 0 | 누적 고유 id: 5610\n",
      "새로 나온 트윗 없음. empty_scrolls=10\n",
      "여러 번 스크롤해도 새 트윗이 안 나와서 종료.\n",
      "\n",
      "최종 수집된 트윗 개수(고유 id 기준): 5610\n",
      "중복 제거 후 최종 행 수: 5610\n",
      "CSV 저장 완료\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import json, html\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import InvalidSessionIdException\n",
    "\n",
    "BASE_URL = (\n",
    "    \"https://www.thetrumparchive.com/?utm_source=chatgpt.com\"\n",
    "    \"&startDate=%222017-01-20%22\"\n",
    "    \"&endDate=%222019-02-10%22\"\n",
    "    \"&retweet=%22false%22\"\n",
    "    \"&device=%22All+devices%22\"\n",
    ")\n",
    "\n",
    "SCROLL_PAUSE_SEC = 1.5\n",
    "MAX_EMPTY_SCROLLS = 10\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "all_tweets = []\n",
    "seen_ids = set()\n",
    "\n",
    "try:\n",
    "    print(\"페이지 열기:\", BASE_URL)\n",
    "    driver.get(BASE_URL)\n",
    "\n",
    "    # 트윗 하나라도 뜰 때까지 기다리기\n",
    "    first_tweet = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"div.ttaTweet\"))\n",
    "    )\n",
    "\n",
    "    # 첫 번째 트윗 기준으로, 실제로 스크롤되는 부모 컨테이너 찾기\n",
    "    scroll_target = driver.execute_script(\"\"\"\n",
    "        let el = arguments[0];\n",
    "        while (el) {\n",
    "            const style = window.getComputedStyle(el);\n",
    "            const overflowY = style.overflowY;\n",
    "            if ((overflowY === 'auto' || overflowY === 'scroll') &&\n",
    "                (el.scrollHeight - el.clientHeight) > 50) {\n",
    "                return el;\n",
    "            }\n",
    "            el = el.parentElement;\n",
    "        }\n",
    "        return document.scrollingElement || document.body;\n",
    "    \"\"\", first_tweet)\n",
    "\n",
    "    print(\"스크롤 타겟 찾음\")\n",
    "\n",
    "    empty_scrolls = 0\n",
    "\n",
    "    while True:\n",
    "        html_source = driver.page_source\n",
    "        soup = BeautifulSoup(html_source, \"html.parser\")\n",
    "\n",
    "        new_in_this_round = 0\n",
    "\n",
    "        for div in soup.select(\"div.ttaTweet\"):\n",
    "            raw = div.get(\"data-tweet\")\n",
    "            if not raw:\n",
    "                continue\n",
    "\n",
    "            data = json.loads(html.unescape(raw))\n",
    "            ts = data.get(\"date\")\n",
    "            tweet_id = data.get(\"id\")\n",
    "\n",
    "            if ts is None or tweet_id is None:\n",
    "                continue\n",
    "\n",
    "            if tweet_id in seen_ids:\n",
    "                continue\n",
    "            seen_ids.add(tweet_id)\n",
    "\n",
    "            dt_utc = datetime.fromtimestamp(ts / 1000.0, tz=timezone.utc)\n",
    "\n",
    "            inner_html = html.unescape(data.get(\"text\", \"\"))\n",
    "            inner_soup = BeautifulSoup(inner_html, \"html.parser\")\n",
    "            text = inner_soup.get_text(\" \", strip=True)\n",
    "\n",
    "            t = {\n",
    "                \"datetime_utc\": dt_utc.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"id\": tweet_id,\n",
    "                \"text\": text,\n",
    "                \"retweets\": data.get(\"retweets\"),\n",
    "                \"favorites\": data.get(\"favorites\"),\n",
    "                \"source\": data.get(\"source\"),\n",
    "            }\n",
    "            all_tweets.append(t)\n",
    "            new_in_this_round += 1\n",
    "\n",
    "        print(f\"이번 라운드 새 트윗: {new_in_this_round} | 누적 고유 id: {len(seen_ids)}\")\n",
    "\n",
    "        if new_in_this_round == 0:\n",
    "            empty_scrolls += 1\n",
    "            print(f\"새로 나온 트윗 없음. empty_scrolls={empty_scrolls}\")\n",
    "            if empty_scrolls >= MAX_EMPTY_SCROLLS:\n",
    "                print(\"여러 번 스크롤해도 새 트윗이 안 나와서 종료.\")\n",
    "                break\n",
    "        else:\n",
    "            empty_scrolls = 0\n",
    "\n",
    "        # 실제 스크롤 컨테이너를 아래로 내리기\n",
    "        driver.execute_script(\n",
    "            \"arguments[0].scrollTop = arguments[0].scrollHeight;\",\n",
    "            scroll_target\n",
    "        )\n",
    "        time.sleep(SCROLL_PAUSE_SEC)\n",
    "\n",
    "except InvalidSessionIdException:\n",
    "    print(\"중간에 브라우저 세션이 끊어졌어요. 여기까지 저장합니다.\")\n",
    "\n",
    "finally:\n",
    "    try:\n",
    "        driver.quit()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(\"\\n최종 수집된 트윗 개수(고유 id 기준):\", len(seen_ids))\n",
    "    df = pd.DataFrame(all_tweets)\n",
    "\n",
    "    if not df.empty:\n",
    "        df = df.drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
    "        print(\"중복 제거 후 최종 행 수:\", len(df))\n",
    "\n",
    "        df.to_csv(\n",
    "            r\"C:\\Users\\shinchaewon\\Desktop\\trump_tweets_2017_20190210_fixed.csv\",\n",
    "            index=False,\n",
    "            encoding=\"utf-8-sig\",\n",
    "        )\n",
    "        print(\"CSV 저장 완료\")\n",
    "    else:\n",
    "        print(\"수집된 데이터가 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66a37ce4-75b9-4ac3-aa27-397ac8870c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "합치기 전 전체 행수: 16924\n",
      "중복 제거 후 행수: 16924\n",
      "완성: C:\\Users\\shinchaewon\\Desktop\\trump_tweets_2016_2021.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) 파일 로드\n",
    "df1 = pd.read_csv(r\"C:\\Users\\shinchaewon\\Desktop\\텍스트마이닝\\trump_tweets_2017_2021_merged_sorted.csv\")\n",
    "df2 = pd.read_csv(r\"C:\\Users\\shinchaewon\\Desktop\\trump_tweets_2017_2021_full.csv\")\n",
    "\n",
    "# 2) 하나로 합치기\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "print(\"합치기 전 전체 행수:\", len(df))\n",
    "\n",
    "# 3) 중복 제거 (id 기준)\n",
    "df = df.drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"중복 제거 후 행수:\", len(df))\n",
    "\n",
    "# 4) datetime_utc → datetime 타입으로 변환\n",
    "df[\"datetime_utc\"] = pd.to_datetime(df[\"datetime_utc\"], errors=\"coerce\")\n",
    "\n",
    "# 5) 시간 순으로 정렬\n",
    "df = df.sort_values(by=\"datetime_utc\").reset_index(drop=True)\n",
    "\n",
    "# 6) 최종 저장\n",
    "output_path = r\"C:\\Users\\shinchaewon\\Desktop\\trump_tweets_2016_2021.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"완성:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a315bc96-0934-44dd-ba7e-327751a61cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 columns: ['datetime_utc', 'id', 'text', 'retweets', 'favorites']\n",
      "df2 columns: ['datetime_utc', 'id', 'text', 'retweets', 'favorites', 'source']\n",
      "합치기 전 전체 행수: 16924\n",
      "중복 제거 후 행수: 16924\n",
      "파싱 실패한 날짜 수: 364\n",
      "완성: C:\\Users\\shinchaewon\\Desktop\\trump_tweets_2016_.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) 파일 로드\n",
    "df1 = pd.read_csv(r\"C:\\Users\\shinchaewon\\Desktop\\텍스트마이닝\\trump_tweets_2017_2021_merged_sorted.csv\")\n",
    "df2 = pd.read_csv(r\"C:\\Users\\shinchaewon\\Desktop\\trump_tweets_2017_2021_full.csv\")\n",
    "\n",
    "s = df['datetime_utc'].astype(str).str.strip()\n",
    "s = s.str.replace(' UTC', '', regex=False)\n",
    "\n",
    "df['datetime_utc'] = pd.to_datetime(s, errors='raise', utc=True)\n",
    "\n",
    "print(\"df1 columns:\", df1.columns.tolist())\n",
    "print(\"df2 columns:\", df2.columns.tolist())\n",
    "\n",
    "# 2) 하나로 합치기\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "print(\"합치기 전 전체 행수:\", len(df))\n",
    "\n",
    "# 3) 중복 제거 (id 기준)\n",
    "df = df.drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
    "print(\"중복 제거 후 행수:\", len(df))\n",
    "\n",
    "# 4) datetime 변환\n",
    "df[\"datetime_utc\"] = pd.to_datetime(df[\"datetime_utc\"], errors=\"coerce\")\n",
    "\n",
    "# datetime 파싱이 안 된 행 체크\n",
    "bad_dates = df[\"datetime_utc\"].isna().sum()\n",
    "print(\"파싱 실패한 날짜 수:\", bad_dates)\n",
    "\n",
    "# 5) 정렬\n",
    "df = df.sort_values(by=\"datetime_utc\").reset_index(drop=True)\n",
    "\n",
    "# 6) 저장\n",
    "output_path = r\"C:\\Users\\shinchaewon\\Desktop\\trump_tweets_2016_.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"완성:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee251d8-0237-4f13-8595-5301db1faea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
